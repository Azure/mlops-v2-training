{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient, command, Input, Output, load_component\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Data, Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter details of your AML workspace\n",
    "subscription_id = \"<subscription_id>\"\n",
    "resource_group = \"<resouce_group_name>\"\n",
    "workspace = \"<workspace_name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1670200031039
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Endpoint\n",
    "\n",
    "**Batch endpoints** are endpoints that are used to do batch inferencing on large volumes of data over a period of time. \n",
    "\n",
    "**Batch endpoints** receive pointers to data and run jobs asynchronously to process the data in parallel on compute clusters. Batch endpoints store outputs to a data store for further analysis.\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/endpoint_batch_concept.png\" width = \"700px\" alt=\"Concept batch endpoint\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Batch Compute Cluster (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gather": {
     "logged": 1668247613855
    }
   },
   "source": [
    "``` python\n",
    "# create compute cluster to be used by batch cluster\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "my_cluster = AmlCompute(\n",
    "    name=\"batch-cluster\",\n",
    "    type=\"amlcompute\", \n",
    "    size=\"STANDARD_DS3_V2\", \n",
    "    min_instances=0, \n",
    "    max_instances=3,\n",
    "    location=\"westeurope\", \t\n",
    ")\n",
    "ml_client.compute.begin_create_or_update(my_cluster)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f085c2d3550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "try:\n",
    "    ml_client.compute.get(name=\"cpu-test\")\n",
    "    print(\"Compute already exists\")\n",
    "\n",
    "except:\n",
    "    print(\"Compute not found; Proceding to create\")\n",
    "\n",
    "    my_cluster = AmlCompute(\n",
    "        name=\"batch-cluster\",\n",
    "        type=\"amlcompute\", \n",
    "        size=\"STANDARD_DS3_V2\", \n",
    "        min_instances=0, \n",
    "        max_instances=3,\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(my_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Batch Endpoint\n",
    "\n",
    "We can create the **batch endpoint** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_batch_endpoint.png\" width = \"700px\" alt=\"Create batch endpoint cli vs sdk\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1668247623872
    }
   },
   "outputs": [],
   "source": [
    "# create batch endpoint\n",
    "from azure.ai.ml.entities import BatchEndpoint\n",
    "import random\n",
    "\n",
    "rand = random.randint(0, 10000)\n",
    "\n",
    "endpoint_name = f\"taxi-batch-endpoint-{rand}\"\n",
    "batch_endpoint = BatchEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description=\"Taxi batch endpoint\",\n",
    "    tags={\"model\": \"taxi-model@latest\"},\n",
    ")\n",
    "\n",
    "poller = ml_client.begin_create_or_update(batch_endpoint)\n",
    "poller.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint creation succeeded\n",
      "{'additional_properties': {}, 'id': '/subscriptions/14585b9f-5c83-4a76-8055-42149123f99f/resourceGroups/mldemorg/providers/Microsoft.MachineLearningServices/workspaces/mldemo/batchEndpoints/taxi-batch-endpoint-6853', 'name': 'taxi-batch-endpoint-6853', 'type': 'Microsoft.MachineLearningServices/workspaces/batchEndpoints', 'system_data': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f085c30ceb0>, 'tags': {'model': 'taxi-model@latest'}, 'location': 'eastus2', 'identity': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity object at 0x7f085c30e620>, 'kind': None, 'properties': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.BatchEndpointDetails object at 0x7f085c30e200>, 'sku': None}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.exceptions import DeploymentException\n",
    "\n",
    "status = poller.status()\n",
    "if status != \"Succeeded\":\n",
    "    raise DeploymentException(status)\n",
    "else:\n",
    "    print(\"Endpoint creation succeeded\")\n",
    "    endpoint = poller.result()\n",
    "    print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Batch Deployment\n",
    "\n",
    "We can create the **batch deployment** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_batch_deployment.png\" width = \"700px\" alt=\"Create batch deployment cli vs sdk\">\n",
    "</center>\n",
    "\n",
    "Note that if you're deploying **MLFlow models**, there's no need to provide **a scoring script** and execution **environment**, as both are autogenerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1668247892781
    }
   },
   "outputs": [],
   "source": [
    "# create batch deployment\n",
    "from azure.ai.ml.entities import BatchDeployment, Model, Environment\n",
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "\n",
    "model = \"taxi-model@latest\"\n",
    "\n",
    "batch_deployment = BatchDeployment(\n",
    "    name=\"taxi-batch-dp\",\n",
    "    description=\"this is a sample batch deployment\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=model,\n",
    "    compute=\"batch-cluster\",\n",
    "    instance_count=2,\n",
    "    max_concurrency_per_instance=2,\n",
    "    mini_batch_size=10,\n",
    "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "    output_file_name=\"predictions.csv\",\n",
    ")\n",
    "\n",
    "poller = ml_client.begin_create_or_update(batch_deployment)\n",
    "poller.wait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Set deployment as the default deployment in the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1668249096086
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "batch_endpoint = ml_client.batch_endpoints.get(endpoint_name)\n",
    "batch_endpoint.defaults.deployment_name = batch_deployment.name\n",
    "poller = ml_client.batch_endpoints.begin_create_or_update(batch_endpoint)\n",
    "poller.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Invoke and Test Endpoint\n",
    "\n",
    "We can invoke the **batch deployment** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/invoke_batch_deployment.png\" width = \"700px\" alt=\"Invoke batch deployment cli vs sdk\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1668689480461
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading taxi-batch.csv\u001b[32m (< 1 MB): 100%|██████████| 133k/133k [00:00<00:00, 7.89MB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.ai.ml._restclient.v2020_09_01_dataplanepreview.models._models_py3.BatchJobResource at 0x7f085c160460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke and test endpoint\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "input = Input(path=\"../../data/taxi-batch.csv\", \n",
    "              type=AssetTypes.URI_FILE, \n",
    "              mode=InputOutputModes.DOWNLOAD)\n",
    "\n",
    "\n",
    "# invoke the endpoint for batch scoring job\n",
    "ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    input=input,\n",
    "    deployment_name=\"taxi-batch-dp\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
